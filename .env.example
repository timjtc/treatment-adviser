# LLM Provider Configuration (flexible multi-provider support)
# PROVIDER can be: openrouter, openai, anthropic, ollama
PROVIDER=openrouter

# API Key for the chosen provider (or use provider-specific key below)
# Note: Ollama doesn't need an API key
PROVIDER_API_KEY=your_api_key_here

# Provider-specific API Keys (used as fallback if PROVIDER_API_KEY not set)
OPENROUTER_API_KEY=your_openrouter_key_here
OPENAI_API_KEY=your_openai_key_here
ANTHROPIC_API_KEY=your_anthropic_key_here

# Model to use (format depends on provider)
# OpenRouter examples: google/gemini-2.0-flash-exp:free, meta-llama/llama-3.1-8b-instruct:free
# OpenAI examples: gpt-4, gpt-4o, gpt-3.5-turbo
# Anthropic examples: claude-3-5-sonnet-20241022, claude-3-opus-20240229
# Ollama examples: llama3.2, llama3.1:8b, qwen2.5:7b, deepseek-r1:7b, medllama2
PROVIDER_MODEL=google/gemini-2.0-flash-exp:free

# Temperature setting (0.3 recommended for medical reasoning)
PROVIDER_TEMPERATURE=0.3

# App URL for OpenRouter HTTP-Referer header
NEXT_PUBLIC_APP_URL=http://localhost:3000

# Ollama Configuration (only used when PROVIDER=ollama)
OLLAMA_BASE_URL=http://localhost:11434/v1

# Optional: OpenFDA API Key (higher rate limits - 1000 req/min vs 240)
# Get free key at: https://open.fda.gov/apis/authentication/
OPENFDA_API_KEY=

DB_URL=vmi2635135.contaboserver.net
DB_USER=postgres
DB_PASSWORD=your_db_password_here